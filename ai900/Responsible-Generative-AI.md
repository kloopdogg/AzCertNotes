# Responsible Generative AI

With the powerful generative AI capabilities available, all involved must adopt a responsible approach that identifies, measures, and mitigates risks.

The Microsoft guidance for responsible generative AI defines a four stage process to develop and implement a plan for responsible AI when using generative models. The four stages in the process are:

1. **Identify potential harms** that are relevant to your planned solution.
    - Identity way to generate content:
        - Offensive, pejorative, or discriminatory.
        - Contains factual inaccuracies.
        - Encourages or supports illegal or unethical behavior or practices
    - Steps:
        - Identify potential harms
        - Prioritize identified harms
        - Test and verify the prioritized harms
        - Document and share the verified harms
2. Measure the presence of these harms in the outputs generated by your solution.
    - Prepare and submit prompts to test for harm
    - Manual and automatic testing
3. Mitigate the harms at multiple layers in your solution to minimize their presence and impact, and ensure transparent communication about potential risks to users.
    - Layers
        - Model
            - Model selection
            - Fine tuning
        - Safety System
            - Content filters
            - Abuse detection algorithms
        - Metaprompt and grounding
            - Metaprompts
            - Prompt engineering for grounding
            - RAG to retrieve context from trusted sources
        - User experience
            - Constrain inputs to specific subjects or types
            - Input/output validation
4. Operate the solution responsibly by defining and following a deployment and operational readiness plan.

## Releasing an AI Solution
Before release, perform pre-release compliance reviews:
- Legal
- Privacy
- Security
- Accessibility

A successful release requires some planning and preparation. Consider the following guidelines:

- **Devise a phased delivery plan** that enables you to release the solution initially to restricted group of users. This approach enables you to gather feedback and identify problems before releasing to a wider audience.
- **Create an incident response plan** that includes estimates of the time taken to respond to unanticipated incidents.
- **Create a rollback plan** that defines the steps to revert the solution to a previous state in the event of an incident.
- **Implement the capability to immediately block harmful system responses** when they're discovered.
Implement a capability to block specific users, applications, or client IP addresses in the event of system misuse.
- **Implement a way for users to provide feedback and report issues**. In particular, enable users to report generated content as "inaccurate", "incomplete", "harmful", "offensive", or otherwise problematic.
- **Track telemetry data** that enables you to determine user satisfaction and identify functional gaps or usability challenges. Telemetry collected should comply with privacy laws and your own organization's policies and commitments to user privacy.

**Responsible AI Impact Assessment** \
Defines a process for assessing the impact an AI
system may have on people, organizations, and
society. \
[Template](https://blogs.microsoft.com/wp-content/uploads/prod/sites/5/2022/06/Microsoft-RAI-Impact-Assessment-Template.pdf)